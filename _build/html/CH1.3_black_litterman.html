

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Black-Litterman model for portfolio allocation &#8212; Bayesian Methods in Asset Pricing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'CH1.3_black_litterman';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 2: The cross section of asset returns" href="CH2_cross_section.html" />
    <link rel="prev" title="Bayesian inference and computation" href="CH1.2_bayes.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="landing_intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/BAP_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/BAP_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="landing_intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="CH1_allocation.html">Chapter 1: Risk, return and allocation</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="CH1.1_returns_mvo.html">Returns, risk and diversification</a></li>
<li class="toctree-l2"><a class="reference internal" href="CH1.2_bayes.html">Bayesian inference and computation</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Black-Litterman model for portfolio allocation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="CH2_cross_section.html">Chapter 2: The cross section of asset returns</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="CH2.1_cross_section_factors.html">The cross-section of stock returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="CH2.2_linear_models_bayesian.html">Linear models: classic and Bayesian approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="CH2.3_hierarchical_bayesian_capm.html">Bayesian techniques for factor models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="CH3_time_series.html">Chapter 3: Time series</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="CH3.1_timeseries_stockprices.html">Time series of stock prices and returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="CH3.2_bayesian_timeseries.html">Time series modeling: classical and Bayesian approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="CH3.3_ARIMA_SV_ES_VAR.html">Bayesian state space approach for nonsynchronous trading</a></li>

</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ref_chapter.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/thomasmartins/BAP_book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/thomasmartins/BAP_book/issues/new?title=Issue%20on%20page%20%2FCH1.3_black_litterman.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/CH1.3_black_litterman.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Black-Litterman model for portfolio allocation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incorporating-subjective-views">Incorporating subjective views</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conjugate-priors-versus-mcmc">Conjugate priors versus MCMC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-references-for-this-section">Additional references for this section</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="black-litterman-model-for-portfolio-allocation">
<h1>Black-Litterman model for portfolio allocation<a class="headerlink" href="#black-litterman-model-for-portfolio-allocation" title="Permalink to this heading">#</a></h1>
<p>Now that we are familiarized with both mean-variance optimization and Bayesian inference, we can take a look at one of the most important models in finance: the Black-Litterman (B-L) model. There are many different implementations for the B-L model, and our main reference shall be Idzorek (2007).</p>
<p>The Black-Litterman model is a combination of both ideas: it relies on return data in order to find optimal portfolio allocations, however it allows for the incorporation of investors’ opinions about future returns. This is done in a Bayesian setting via prior distributions.</p>
<p>The B-L formula for estimated mean returns is</p>
<p><span class="math notranslate nohighlight">\(\hat{\mu}_{BL} = [(\tau \Sigma)^{-1} + P' \Omega^{-1} P]^{-1} [(\tau \Sigma)^{-1} \Pi + P' \Omega^{-1} Q]\)</span>.</p>
<p>Now let’s break it down. First of all, the B-L model does not use the historical (sample) mean returns as the prior estimate of mean returns, as it tends to produce extreme long and short positions in unconstrained settings due to sample uncertainty. Instead, it relies on implied market equilibrium returns, <span class="math notranslate nohighlight">\(\Pi\)</span>, as the prior estimate for mean returns. The formula for <span class="math notranslate nohighlight">\(\Pi\)</span> consists of</p>
<p><span class="math notranslate nohighlight">\(\Pi = \lambda \Sigma w_{mkt}\)</span>.</p>
<p>Starting with the more simple parameters, <span class="math notranslate nohighlight">\(\Sigma\)</span> is the sample covariance matrix of the excess (i.e. observed minus risk-free rate) returns and <span class="math notranslate nohighlight">\(w_{mkt}\)</span> is the market capitalization weight of all assets. <span class="math notranslate nohighlight">\(\lambda\)</span> is the market price of risk, calculated by dividing the mean of excess returns of the market portfolio by its variance:</p>
<p><span class="math notranslate nohighlight">\(\lambda = \frac{r_m - r_f}{\sigma^2}\)</span>.</p>
<p>With all three components, we can obtain the values for <span class="math notranslate nohighlight">\(\Pi\)</span>, an <span class="math notranslate nohighlight">\(N \times 1\)</span> vector where <span class="math notranslate nohighlight">\(N\)</span> is our number of assets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="nn">yf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">data</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;QQQ SCHP SPY XLE XLF&quot;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s2">&quot;2015-01-01&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;2022-01-01&quot;</span><span class="p">)[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span>
<span class="n">risk_free</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;^IRX&quot;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s2">&quot;2015-01-01&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;2022-01-01&quot;</span><span class="p">)[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[                       0%%                      ]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[*******************   40%%                      ]  2 of 5 completed
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[**********************60%%***                   ]  3 of 5 completed
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[**********************80%%************          ]  4 of 5 completed
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[*********************100%%**********************]  5 of 5 completed
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[*********************100%%**********************]  1 of 1 completed
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tickers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;QQQ&quot;</span><span class="p">,</span> <span class="s2">&quot;SCHP&quot;</span><span class="p">,</span> <span class="s2">&quot;SPY&quot;</span><span class="p">,</span> <span class="s2">&quot;XLE&quot;</span><span class="p">,</span> <span class="s2">&quot;XLF&quot;</span><span class="p">]</span>
<span class="n">assets_volume</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tickers</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">tickers</span><span class="p">)):</span>
    <span class="n">assets_volume</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">Ticker</span><span class="p">(</span><span class="n">tickers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;totalAssets&quot;</span><span class="p">]</span>

<span class="n">assets_volume</span> <span class="c1"># obtaining market capitalizations that will be used to compute w_mkt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2.29965267e+11, 1.14854953e+10, 4.97007821e+11, 3.61794560e+10,
       3.40377272e+10])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_mkt</span> <span class="o">=</span> <span class="n">assets_volume</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">assets_volume</span><span class="p">)</span>
<span class="n">w_mkt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.28437265, 0.01420284, 0.61459468, 0.04473914, 0.0420907 ])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>QQQ</th>
      <th>SCHP</th>
      <th>SPY</th>
      <th>XLE</th>
      <th>XLF</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015-01-02</th>
      <td>102.940002</td>
      <td>54.509998</td>
      <td>205.429993</td>
      <td>79.529999</td>
      <td>20.089357</td>
    </tr>
    <tr>
      <th>2015-01-05</th>
      <td>101.430000</td>
      <td>54.560001</td>
      <td>201.720001</td>
      <td>76.239998</td>
      <td>19.666937</td>
    </tr>
    <tr>
      <th>2015-01-06</th>
      <td>100.070000</td>
      <td>54.599998</td>
      <td>199.820007</td>
      <td>75.120003</td>
      <td>19.366369</td>
    </tr>
    <tr>
      <th>2015-01-07</th>
      <td>101.360001</td>
      <td>54.599998</td>
      <td>202.309998</td>
      <td>75.279999</td>
      <td>19.569456</td>
    </tr>
    <tr>
      <th>2015-01-08</th>
      <td>103.300003</td>
      <td>54.580002</td>
      <td>205.899994</td>
      <td>76.970001</td>
      <td>19.861900</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mkt_portfolio_returns</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span> <span class="o">@</span> <span class="n">w_mkt</span>
<span class="c1"># multiply by 252 so we get annualized mean and variance</span>
<span class="n">market_mean_returns</span> <span class="o">=</span> <span class="n">mkt_portfolio_returns</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="mi">252</span>
<span class="n">market_var_returns</span> <span class="o">=</span> <span class="n">mkt_portfolio_returns</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">*</span> <span class="mi">252</span>
<span class="n">mean_risk_free</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">risk_free</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span>

<span class="n">lamb</span> <span class="o">=</span> <span class="p">(</span><span class="n">market_mean_returns</span> <span class="o">-</span> <span class="n">mean_risk_free</span><span class="p">)</span><span class="o">/</span><span class="n">market_var_returns</span>
<span class="n">lamb</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.22617538788212
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">excess_returns</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">risk_free</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">/</span><span class="mi">100</span><span class="p">)[</span><span class="s1">&#39;Close&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="p">(</span><span class="n">excess_returns</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span> <span class="o">*</span> <span class="mi">252</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">Sigma</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.06281343, 0.01770594, 0.05301843, 0.05310712, 0.05194   ],
       [0.01770594, 0.0205251 , 0.01754405, 0.01939368, 0.01648125],
       [0.05301843, 0.01754405, 0.05022575, 0.05863181, 0.0550494 ],
       [0.05310712, 0.01939368, 0.05863181, 0.11825733, 0.07537013],
       [0.05194   , 0.01648125, 0.0550494 , 0.07537013, 0.07474093]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pi</span> <span class="o">=</span> <span class="n">lamb</span> <span class="o">*</span> <span class="p">(</span><span class="n">Sigma</span> <span class="o">@</span> <span class="n">w_mkt</span><span class="p">)</span>
<span class="n">Pi</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.23354224, 0.07467839, 0.21610483, 0.25304465, 0.23394146])
</pre></div>
</div>
</div>
</div>
<section id="incorporating-subjective-views">
<h2>Incorporating subjective views<a class="headerlink" href="#incorporating-subjective-views" title="Permalink to this heading">#</a></h2>
<p>Now, with our prior estimates for the mean returns in hand, we can begin to incorporate the subjective views onto the Black-Litterman model. This is the purpose of matrices <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>Suppose we have the following subjective views:</p>
<ul class="simple">
<li><p>QQQ will rise 10%</p></li>
<li><p>SPY will drop 5%</p></li>
<li><p>XLE will outperform XLF by 8%</p></li>
</ul>
<p>The first two are <em>absolute</em> views, and the last one is a <em>relative</em> view.</p>
<p><span class="math notranslate nohighlight">\(Q\)</span> is the <span class="math notranslate nohighlight">\(K \times 1\)</span> matrix that contains these views, where <span class="math notranslate nohighlight">\(K\)</span> is the number of views.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.08</span><span class="p">])</span>
<span class="n">Q</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.1 , -0.05,  0.08])
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(P\)</span> is the picking matrix, which will map the views onto the assets. It has dimensions <span class="math notranslate nohighlight">\(K \times N\)</span>.</p>
<p>For absolute views, the rows have <span class="math notranslate nohighlight">\(1\)</span> for the corresponding asset and <span class="math notranslate nohighlight">\(0\)</span> for all others. For relative views, it has positive numbers for the outperforming assets and negative numbers for the underperforming assets, with all numbers together adding up to zero.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span> <span class="c1"># our assets are ordered QQQ, SCHP, SPY, XLE, XLF</span>
<span class="n">P</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 1,  0,  0,  0,  0],
       [ 0,  0,  1,  0,  0],
       [ 0,  0,  0,  1, -1]])
</pre></div>
</div>
</div>
</div>
<p>The last components of the Black-Litterman formula are the matrix <span class="math notranslate nohighlight">\(\Omega\)</span> and the quantity <span class="math notranslate nohighlight">\(\tau\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\Omega\)</span> is referred to as the confidence matrix, as it represents the uncertainty the investor has in their views. It is the covariance matrix of our views, meaning that our views are actually of the form <span class="math notranslate nohighlight">\(Q + \boldsymbol{\varepsilon}\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{\varepsilon} \sim MVN(\boldsymbol{0}, \Omega)\)</span></p>
<p><span class="math notranslate nohighlight">\(\Omega\)</span> is a diagonal matrix, as the views have zero correlation, i.e., are independent of each other. As it is quite difficult to summarise the uncertainty contained in each view, many methods for its calculation have been proposed. We shall stick to Idzorek’s method, which allows for users to specify their confidence in each view as a percentage.</p>
<p>The original method by Idzorek estimates the view variances, <span class="math notranslate nohighlight">\(\omega_i\)</span>, via least squares. Walters (2014) proposes a closed-form method.</p>
<p>Denoting by <span class="math notranslate nohighlight">\(conf\)</span> the confidence in each of our views, which can range from zero to 100%, we shall have</p>
<p><span class="math notranslate nohighlight">\(\alpha = \frac{1-conf}{conf}\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\Omega = \tau \alpha P \Sigma P'\)</span>.</p>
<p>This leaves us with <span class="math notranslate nohighlight">\(\tau\)</span>. From the B-L formula we can see it is inversely proportional to the weight given to our prior estimate for the mean returns, <span class="math notranslate nohighlight">\(\Pi\)</span>. As <span class="math notranslate nohighlight">\(\Pi\)</span> corresponds to market equilibrium returns, Idzorek cites that, since the uncertainty in the mean is reasonably lower than the uncertainty in the observed historical returns, <span class="math notranslate nohighlight">\(\tau\)</span> should be close to zero. For the sake of simplicity, we set <span class="math notranslate nohighlight">\(\tau = 0.05\)</span> for our example.</p>
<p>Assuming a confidence of 70%, 60% and 40% for each of the views, we can obtain <span class="math notranslate nohighlight">\(\Omega\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">conf</span><span class="p">)</span><span class="o">/</span><span class="n">conf</span>

<span class="n">Omega_diag</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">@</span> <span class="p">(</span><span class="n">P</span> <span class="o">@</span> <span class="n">Sigma</span> <span class="o">@</span> <span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
<span class="n">Omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">Omega_diag</span><span class="p">)</span>
<span class="n">Omega</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00320082, 0.        , 0.        ],
       [0.        , 0.00307898, 0.        ],
       [0.        , 0.        , 0.00331377]])
</pre></div>
</div>
</div>
</div>
<p>Now we can go back to the B-L formula and obtain the Black-Litterman posterior estimates for mean returns</p>
<p><span class="math notranslate nohighlight">\(\hat{\mu}_{BL} = [(\tau \Sigma)^{-1} + P' \Omega^{-1} P]^{-1} [(\tau \Sigma)^{-1} \Pi + P' \Omega^{-1} Q]\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_bl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tau</span><span class="o">*</span><span class="n">Sigma</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Omega</span><span class="p">)</span> <span class="o">@</span> <span class="n">P</span><span class="p">))</span> <span class="o">@</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tau</span><span class="o">*</span><span class="n">Sigma</span><span class="p">)</span> <span class="o">@</span> <span class="n">Pi</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Omega</span><span class="p">)</span> <span class="o">@</span> <span class="n">Q</span><span class="p">))</span>
<span class="n">mu_bl</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.10441575, 0.03377898, 0.09581244, 0.13799624, 0.10041165])
</pre></div>
</div>
</div>
</div>
<p>Compare with the historical mean returns::</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span> <span class="o">*</span> <span class="mi">252</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.21554025,  0.02172902,  0.13575803, -0.00191245,  0.12299622])
</pre></div>
</div>
</div>
</div>
<p>The first part of the B-L formula for the mean returns, <span class="math notranslate nohighlight">\([(\tau \Sigma)^{-1} + P' \Omega^{-1} P]^{-1}\)</span>, is actually the B-L posterior estimate of the returns covariance matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cov_bl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tau</span><span class="o">*</span><span class="n">Sigma</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Omega</span><span class="p">)</span> <span class="o">@</span> <span class="n">P</span><span class="p">))</span>
<span class="n">cov_bl</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.0012, 0.0003, 0.0009, 0.0008, 0.0008],
       [0.0003, 0.0008, 0.0003, 0.0003, 0.0003],
       [0.0009, 0.0003, 0.001 , 0.0012, 0.0011],
       [0.0008, 0.0003, 0.0012, 0.0033, 0.002 ],
       [0.0008, 0.0003, 0.0011, 0.002 , 0.0021]])
</pre></div>
</div>
</div>
</div>
<p>In order to find the allocation weights for the B-L model, we can just plug the posterior mean and covariance estimates into the regular mean-variance optimizer, or find the weights via reverse optimization</p>
<p><span class="math notranslate nohighlight">\(w_{BL} = (\lambda \Sigma)^{-1} \hat{\mu}_{BL}\)</span>.</p>
<p>We can also normalize so that all weights add up to 1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_bl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">lamb</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">)</span> <span class="o">@</span> <span class="n">mu_bl</span>
<span class="n">w_bl</span> <span class="o">=</span> <span class="n">w_bl</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w_bl</span><span class="p">)</span>
<span class="n">w_bl</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.63310352,  0.03354538,  0.12826964,  0.46333698, -0.25825552])
</pre></div>
</div>
</div>
</div>
<p>The library PyPortfolioOpt contains straightforward implementations of the Black-Litterman procedures we have seen up to here:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypfopt</span> <span class="kn">import</span> <span class="n">black_litterman</span><span class="p">,</span> <span class="n">risk_models</span>

<span class="c1"># pypfopt only allows for constant risk-free rates, we shall use the mean of our sample</span>
<span class="n">lamb</span> <span class="o">=</span> <span class="n">black_litterman</span><span class="o">.</span><span class="n">market_implied_risk_aversion</span><span class="p">((</span><span class="n">data</span> <span class="o">@</span> <span class="n">w_mkt</span><span class="p">),</span> <span class="n">risk_free_rate</span><span class="o">=</span><span class="n">mean_risk_free</span><span class="p">)</span>
<span class="n">Pi</span> <span class="o">=</span> <span class="n">black_litterman</span><span class="o">.</span><span class="n">market_implied_prior_returns</span><span class="p">(</span><span class="n">assets_volume</span><span class="p">,</span> <span class="n">lamb</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">risk_free_rate</span><span class="o">=</span><span class="n">mean_risk_free</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\USUARIO\anaconda3\envs\pymc_env\lib\site-packages\pypfopt\black_litterman.py:44: RuntimeWarning: If cov_matrix is not a dataframe, market cap index must be aligned to cov_matrix
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lamb</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.31432063009964
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pi</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.24640609, 0.08422883, 0.22860499, 0.26631527, 0.24681364])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypfopt.black_litterman</span> <span class="kn">import</span> <span class="n">BlackLittermanModel</span>

<span class="n">cov_matrix</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span> <span class="o">*</span> <span class="mi">252</span><span class="p">)</span>
<span class="n">bl</span> <span class="o">=</span> <span class="n">BlackLittermanModel</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">pi</span><span class="o">=</span><span class="n">Pi</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="n">Q</span><span class="p">,</span> <span class="n">P</span><span class="o">=</span><span class="n">P</span><span class="p">,</span> <span class="n">omega</span><span class="o">=</span><span class="n">Omega</span><span class="p">,</span> <span class="n">view_confidences</span><span class="o">=</span><span class="n">conf</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">risk_free_rate</span><span class="o">=</span><span class="n">mean_risk_free</span><span class="p">)</span>

<span class="n">mu_bl</span> <span class="o">=</span> <span class="n">bl</span><span class="o">.</span><span class="n">bl_returns</span><span class="p">()</span>
<span class="n">mu_bl</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>QQQ     0.129196
SCHP    0.088260
SPY     0.125207
XLE     0.166409
XLF     0.128978
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="conjugate-priors-versus-mcmc">
<h2>Conjugate priors versus MCMC<a class="headerlink" href="#conjugate-priors-versus-mcmc" title="Permalink to this heading">#</a></h2>
<p>Now let’s go back to the B-L formula:</p>
<p><span class="math notranslate nohighlight">\(\hat{\mu}_{BL} = [(\tau \Sigma)^{-1} + P' \Omega^{-1} P]^{-1} [(\tau \Sigma)^{-1} \Pi + P' \Omega^{-1} Q]\)</span></p>
<p>The reason we can obtain a closed-form expression for <span class="math notranslate nohighlight">\(\hat{\mu}_{BL}\)</span> is because the Black-Litterman model makes use of conjugate priors.</p>
<p>The parameter we wish to make inference for is the vector of asset mean returns, or expected returns.</p>
<p>Our prior distribution for the mean returns is a multivariate normal. The mean vector of that prior distribution is <span class="math notranslate nohighlight">\(\Pi\)</span>, which comes from market equilibrium, is calculated from the data. The prior covariance is <span class="math notranslate nohighlight">\(\tau \Sigma\)</span>, and <span class="math notranslate nohighlight">\(\Sigma\)</span> is the sample covariance, also calculated from market return data.</p>
<p>The subjective investor views, which are the B-L “likelihood”, also follow a multivariate normal distribution.</p>
<p>Bayesian conjugate analysis shows us that, a mean vector <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> of a multivariate normal distribution with covariance <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>, with prior distribution</p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\mu} \sim MVN(\boldsymbol{\mu}_0, \boldsymbol{\Sigma}_0)\)</span>,</p>
<p>shall have the posterior covariance</p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_P = [\boldsymbol{\Sigma}_0^{-1} + n \boldsymbol{\Sigma}^{-1}]^{-1}\)</span></p>
<p>and posterior mean</p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\mu}_P = \boldsymbol{\Sigma}_P [\boldsymbol{\Sigma}_0^{-1} \boldsymbol{\mu}_0 + n \boldsymbol{\Sigma}^{-1} \mathbf{\bar{x}}]\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\bar{x}}\)</span> is the sample mean.</p>
<p>These expressions are similar to the B-L formula.</p>
<p>But what if we wanted to depart from the conjugate priors in the B-L framework?</p>
<p>MCMC allows us to do that. Schepel (2019) presents us with a few extensions of the B-L model, some making use of MCMC algorithms. Let’s assume the first model to be estimated by MCMC is similar to the classical B-L model:</p>
<p><span class="math notranslate nohighlight">\(\mu \sim N(\Pi, \tau \Sigma)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(Q|\mu \sim N(P\mu, \Omega)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(r \sim N(\mu, \Sigma)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="nn">pm</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_normal</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">tau</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">Q_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;Q&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">mu</span><span class="p">),</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">Q</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;returns&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="n">trace_normal</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;adapt_diag&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing NUTS using adapt_diag...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Multiprocess sampling (4 chains in 4 jobs)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NUTS: [mu]
</pre></div>
</div>
<div class="output text_html">
    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [12000/12000 01:38<00:00 Sampling 4 chains, 0 divergences]
    </div>
    </div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 113 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_normal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mu[0]</th>
      <td>0.004</td>
      <td>0.006</td>
      <td>-0.007</td>
      <td>0.015</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2097.0</td>
      <td>2532.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[1]</th>
      <td>0.001</td>
      <td>0.003</td>
      <td>-0.005</td>
      <td>0.007</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3306.0</td>
      <td>4637.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[2]</th>
      <td>0.004</td>
      <td>0.005</td>
      <td>-0.006</td>
      <td>0.013</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1811.0</td>
      <td>2345.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[3]</th>
      <td>0.004</td>
      <td>0.008</td>
      <td>-0.010</td>
      <td>0.019</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2244.0</td>
      <td>3328.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[4]</th>
      <td>0.004</td>
      <td>0.006</td>
      <td>-0.009</td>
      <td>0.015</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1948.0</td>
      <td>2742.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_normal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[&lt;Axes: title={&#39;center&#39;: &#39;mu&#39;}&gt;, &lt;Axes: title={&#39;center&#39;: &#39;mu&#39;}&gt;]],
      dtype=object)
</pre></div>
</div>
<img alt="_images/230cb34c74ea4fd08a78c0c16739c3869b87de20cce1ae6c9ea1f5bbe1bbfd46.png" src="_images/230cb34c74ea4fd08a78c0c16739c3869b87de20cce1ae6c9ea1f5bbe1bbfd46.png" />
</div>
</div>
<p>We can also add a prior for the covariance of returns:</p>
<p><span class="math notranslate nohighlight">\(\mu \sim N(\Pi, \tau \Sigma)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(Q|\mu \sim N(P\mu, \Omega)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\Psi \sim \begin{pmatrix} \sigma_1 &amp; 0 &amp; \ddots \\ 0 &amp; \ddots &amp; 0 \\ \ddots &amp; 0 &amp; \sigma_5 \end{pmatrix} P \begin{pmatrix} \sigma_1 &amp; 0 &amp; \ddots \\ 0 &amp; \ddots &amp; 0 \\ \ddots &amp; 0 &amp; \sigma_5 \end{pmatrix}\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\sigma_i \sim HalfCauchy(1)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(P \sim LKJCorr(1)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(r \sim N(\mu, \Psi)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_normal_cov</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">tau</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">Q_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;Q&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">mu</span><span class="p">),</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">Q</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

    <span class="n">sd_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">chol</span><span class="p">,</span> <span class="n">corr</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">LKJCholeskyCov</span><span class="p">(</span><span class="s1">&#39;Psi&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sd_dist</span><span class="o">=</span><span class="n">sd_0</span><span class="p">,</span> <span class="n">compute_corr</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">r</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;returns&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">,</span> <span class="n">chol</span> <span class="o">=</span> <span class="n">chol</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="n">trace_normal_cov</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;adapt_diag&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing NUTS using adapt_diag...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Multiprocess sampling (4 chains in 4 jobs)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NUTS: [mu, Psi]
</pre></div>
</div>
<div class="output text_html">
    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [12000/12000 06:46<00:00 Sampling 4 chains, 0 divergences]
    </div>
    </div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 421 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_normal_cov</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span><span class="s2">&quot;Psi_stds&quot;</span><span class="p">,</span><span class="s2">&quot;Psi_corr&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\USUARIO\anaconda3\envs\pymc_env\lib\site-packages\arviz\stats\diagnostics.py:592: RuntimeWarning: invalid value encountered in scalar divide
  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mu[0]</th>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.001</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4597.0</td>
      <td>5656.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[1]</th>
      <td>0.000</td>
      <td>0.000</td>
      <td>-0.000</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8070.0</td>
      <td>6229.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[2]</th>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.001</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3706.0</td>
      <td>4692.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[3]</th>
      <td>0.000</td>
      <td>0.000</td>
      <td>-0.001</td>
      <td>0.001</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4952.0</td>
      <td>4904.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[4]</th>
      <td>0.001</td>
      <td>0.000</td>
      <td>-0.000</td>
      <td>0.001</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4001.0</td>
      <td>5099.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[0]</th>
      <td>0.013</td>
      <td>0.000</td>
      <td>0.013</td>
      <td>0.014</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5656.0</td>
      <td>5048.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[1]</th>
      <td>0.003</td>
      <td>0.000</td>
      <td>0.003</td>
      <td>0.003</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9668.0</td>
      <td>5613.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[2]</th>
      <td>0.011</td>
      <td>0.000</td>
      <td>0.011</td>
      <td>0.012</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4198.0</td>
      <td>4848.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[3]</th>
      <td>0.020</td>
      <td>0.000</td>
      <td>0.019</td>
      <td>0.020</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6308.0</td>
      <td>6020.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[4]</th>
      <td>0.015</td>
      <td>0.000</td>
      <td>0.014</td>
      <td>0.015</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4922.0</td>
      <td>5584.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 0]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8000.0</td>
      <td>8000.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 1]</th>
      <td>-0.060</td>
      <td>0.024</td>
      <td>-0.103</td>
      <td>-0.016</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>11196.0</td>
      <td>5834.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 2]</th>
      <td>0.920</td>
      <td>0.004</td>
      <td>0.913</td>
      <td>0.926</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4472.0</td>
      <td>5332.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 3]</th>
      <td>0.510</td>
      <td>0.017</td>
      <td>0.476</td>
      <td>0.542</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5114.0</td>
      <td>6083.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 4]</th>
      <td>0.665</td>
      <td>0.013</td>
      <td>0.639</td>
      <td>0.689</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4478.0</td>
      <td>5402.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 0]</th>
      <td>-0.060</td>
      <td>0.024</td>
      <td>-0.103</td>
      <td>-0.016</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>11196.0</td>
      <td>5834.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 1]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7927.0</td>
      <td>7799.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 2]</th>
      <td>-0.084</td>
      <td>0.023</td>
      <td>-0.126</td>
      <td>-0.040</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10110.0</td>
      <td>6297.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 3]</th>
      <td>0.027</td>
      <td>0.024</td>
      <td>-0.017</td>
      <td>0.071</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6993.0</td>
      <td>6332.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 4]</th>
      <td>-0.170</td>
      <td>0.023</td>
      <td>-0.214</td>
      <td>-0.128</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7544.0</td>
      <td>6723.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 0]</th>
      <td>0.920</td>
      <td>0.004</td>
      <td>0.913</td>
      <td>0.926</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4472.0</td>
      <td>5332.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 1]</th>
      <td>-0.084</td>
      <td>0.023</td>
      <td>-0.126</td>
      <td>-0.040</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10110.0</td>
      <td>6297.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 2]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8020.0</td>
      <td>8000.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 3]</th>
      <td>0.704</td>
      <td>0.012</td>
      <td>0.681</td>
      <td>0.725</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6609.0</td>
      <td>6243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 4]</th>
      <td>0.862</td>
      <td>0.006</td>
      <td>0.850</td>
      <td>0.873</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5624.0</td>
      <td>6175.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 0]</th>
      <td>0.510</td>
      <td>0.017</td>
      <td>0.476</td>
      <td>0.542</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5114.0</td>
      <td>6083.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 1]</th>
      <td>0.027</td>
      <td>0.024</td>
      <td>-0.017</td>
      <td>0.071</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6993.0</td>
      <td>6332.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 2]</th>
      <td>0.704</td>
      <td>0.012</td>
      <td>0.681</td>
      <td>0.725</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6609.0</td>
      <td>6243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 3]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7904.0</td>
      <td>7938.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 4]</th>
      <td>0.753</td>
      <td>0.010</td>
      <td>0.734</td>
      <td>0.772</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7114.0</td>
      <td>6156.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 0]</th>
      <td>0.665</td>
      <td>0.013</td>
      <td>0.639</td>
      <td>0.689</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4478.0</td>
      <td>5402.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 1]</th>
      <td>-0.170</td>
      <td>0.023</td>
      <td>-0.214</td>
      <td>-0.128</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7544.0</td>
      <td>6723.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 2]</th>
      <td>0.862</td>
      <td>0.006</td>
      <td>0.850</td>
      <td>0.873</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5624.0</td>
      <td>6175.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 3]</th>
      <td>0.753</td>
      <td>0.010</td>
      <td>0.734</td>
      <td>0.772</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7114.0</td>
      <td>6156.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 4]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7698.0</td>
      <td>7773.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_normal_cov</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span><span class="s2">&quot;Psi_stds&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[&lt;Axes: title={&#39;center&#39;: &#39;mu&#39;}&gt;, &lt;Axes: title={&#39;center&#39;: &#39;mu&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;Psi_stds&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;Psi_stds&#39;}&gt;]], dtype=object)
</pre></div>
</div>
<img alt="_images/58757db51f5948cfcb0c8b15b3aa4404f0c94b48a344f9f66a70c194435efbc2.png" src="_images/58757db51f5948cfcb0c8b15b3aa4404f0c94b48a344f9f66a70c194435efbc2.png" />
</div>
</div>
<p>We can even suppose returns follow a Student’s t-distribution, instead of a Gaussian, and put a prior on the degrees of freedom parameter:</p>
<p><span class="math notranslate nohighlight">\(\mu \sim N(\Pi, \tau \Sigma)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(Q|\mu \sim N(P\mu, \Omega)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\Psi \sim \begin{pmatrix} \sigma_1 &amp; 0 &amp; \ddots \\ 0 &amp; \ddots &amp; 0 \\ \ddots &amp; 0 &amp; \sigma_5 \end{pmatrix} P \begin{pmatrix} \sigma_1 &amp; 0 &amp; \ddots \\ 0 &amp; \ddots &amp; 0 \\ \ddots &amp; 0 &amp; \sigma_5 \end{pmatrix}\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\sigma_i \sim HalfCauchy(1)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(P \sim LKJCorr(1)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\nu \sim Gamma(2, 10)\)</span>,</p>
<p><span class="math notranslate nohighlight">\(r \sim t(\mu, \Psi, \nu)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">tau</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">Q_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;Q&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">mu</span><span class="p">),</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">Q</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
    
    <span class="n">sd_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">chol</span><span class="p">,</span> <span class="n">corr</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">LKJCholeskyCov</span><span class="p">(</span><span class="s1">&#39;Psi&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sd_dist</span><span class="o">=</span><span class="n">sd_0</span><span class="p">,</span> <span class="n">compute_corr</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="n">r</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvStudentT</span><span class="p">(</span><span class="s1">&#39;returns&#39;</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">nu</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">,</span> <span class="n">chol</span> <span class="o">=</span> <span class="n">chol</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="n">trace_t</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;adapt_diag&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing NUTS using adapt_diag...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Multiprocess sampling (4 chains in 4 jobs)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NUTS: [mu, Psi, nu]
</pre></div>
</div>
<div class="output text_html">
    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [12000/12000 08:59<00:00 Sampling 4 chains, 0 divergences]
    </div>
    </div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 557 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_t</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span><span class="s2">&quot;Psi_stds&quot;</span><span class="p">,</span><span class="s2">&quot;Psi_corr&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\USUARIO\anaconda3\envs\pymc_env\lib\site-packages\arviz\stats\diagnostics.py:592: RuntimeWarning: invalid value encountered in scalar divide
  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>nu</th>
      <td>3.673</td>
      <td>0.174</td>
      <td>3.358</td>
      <td>4.008</td>
      <td>0.002</td>
      <td>0.001</td>
      <td>8051.0</td>
      <td>6034.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[0]</th>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.001</td>
      <td>0.002</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>4654.0</td>
      <td>5954.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[1]</th>
      <td>0.000</td>
      <td>0.000</td>
      <td>-0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>12138.0</td>
      <td>5950.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[2]</th>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>3904.0</td>
      <td>5134.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[3]</th>
      <td>-0.000</td>
      <td>0.000</td>
      <td>-0.001</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>5572.0</td>
      <td>6192.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mu[4]</th>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>4123.0</td>
      <td>5332.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[0]</th>
      <td>0.009</td>
      <td>0.000</td>
      <td>0.008</td>
      <td>0.009</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>4329.0</td>
      <td>5129.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[1]</th>
      <td>0.002</td>
      <td>0.000</td>
      <td>0.002</td>
      <td>0.002</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>8984.0</td>
      <td>6167.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[2]</th>
      <td>0.007</td>
      <td>0.000</td>
      <td>0.007</td>
      <td>0.007</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>3419.0</td>
      <td>4258.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[3]</th>
      <td>0.013</td>
      <td>0.000</td>
      <td>0.012</td>
      <td>0.013</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>4663.0</td>
      <td>5695.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_stds[4]</th>
      <td>0.009</td>
      <td>0.000</td>
      <td>0.009</td>
      <td>0.010</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>3520.0</td>
      <td>5165.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 0]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>8000.0</td>
      <td>8000.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 1]</th>
      <td>-0.085</td>
      <td>0.026</td>
      <td>-0.133</td>
      <td>-0.037</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>10250.0</td>
      <td>5921.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 2]</th>
      <td>0.907</td>
      <td>0.005</td>
      <td>0.898</td>
      <td>0.916</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>5838.0</td>
      <td>6124.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 3]</th>
      <td>0.431</td>
      <td>0.022</td>
      <td>0.391</td>
      <td>0.472</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>6484.0</td>
      <td>6430.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[0, 4]</th>
      <td>0.604</td>
      <td>0.017</td>
      <td>0.572</td>
      <td>0.637</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>5441.0</td>
      <td>5462.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 0]</th>
      <td>-0.085</td>
      <td>0.026</td>
      <td>-0.133</td>
      <td>-0.037</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>10250.0</td>
      <td>5921.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 1]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7227.0</td>
      <td>7094.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 2]</th>
      <td>-0.129</td>
      <td>0.025</td>
      <td>-0.176</td>
      <td>-0.082</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>9405.0</td>
      <td>5958.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 3]</th>
      <td>-0.076</td>
      <td>0.026</td>
      <td>-0.125</td>
      <td>-0.027</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7294.0</td>
      <td>6451.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[1, 4]</th>
      <td>-0.274</td>
      <td>0.024</td>
      <td>-0.319</td>
      <td>-0.230</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7112.0</td>
      <td>5770.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 0]</th>
      <td>0.907</td>
      <td>0.005</td>
      <td>0.898</td>
      <td>0.916</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>5838.0</td>
      <td>6124.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 1]</th>
      <td>-0.129</td>
      <td>0.025</td>
      <td>-0.176</td>
      <td>-0.082</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>9405.0</td>
      <td>5958.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 2]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>8275.0</td>
      <td>8000.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 3]</th>
      <td>0.631</td>
      <td>0.016</td>
      <td>0.602</td>
      <td>0.661</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7663.0</td>
      <td>6425.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[2, 4]</th>
      <td>0.817</td>
      <td>0.009</td>
      <td>0.801</td>
      <td>0.834</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>6259.0</td>
      <td>6378.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 0]</th>
      <td>0.431</td>
      <td>0.022</td>
      <td>0.391</td>
      <td>0.472</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>6484.0</td>
      <td>6430.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 1]</th>
      <td>-0.076</td>
      <td>0.026</td>
      <td>-0.125</td>
      <td>-0.027</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7294.0</td>
      <td>6451.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 2]</th>
      <td>0.631</td>
      <td>0.016</td>
      <td>0.602</td>
      <td>0.661</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7663.0</td>
      <td>6425.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 3]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7912.0</td>
      <td>8000.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[3, 4]</th>
      <td>0.649</td>
      <td>0.015</td>
      <td>0.620</td>
      <td>0.677</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>8393.0</td>
      <td>6476.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 0]</th>
      <td>0.604</td>
      <td>0.017</td>
      <td>0.572</td>
      <td>0.637</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>5441.0</td>
      <td>5462.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 1]</th>
      <td>-0.274</td>
      <td>0.024</td>
      <td>-0.319</td>
      <td>-0.230</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7112.0</td>
      <td>5770.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 2]</th>
      <td>0.817</td>
      <td>0.009</td>
      <td>0.801</td>
      <td>0.834</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>6259.0</td>
      <td>6378.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 3]</th>
      <td>0.649</td>
      <td>0.015</td>
      <td>0.620</td>
      <td>0.677</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>8393.0</td>
      <td>6476.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Psi_corr[4, 4]</th>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7919.0</td>
      <td>7283.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_t</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span><span class="s2">&quot;Psi_stds&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[&lt;Axes: title={&#39;center&#39;: &#39;nu&#39;}&gt;, &lt;Axes: title={&#39;center&#39;: &#39;nu&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;mu&#39;}&gt;, &lt;Axes: title={&#39;center&#39;: &#39;mu&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;Psi_stds&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;Psi_stds&#39;}&gt;]], dtype=object)
</pre></div>
</div>
<img alt="_images/ccbafd8fcd7ee458838940e3d800872cfc9f67edef0b60a4b76e98241ecde0ac.png" src="_images/ccbafd8fcd7ee458838940e3d800872cfc9f67edef0b60a4b76e98241ecde0ac.png" />
</div>
</div>
<p>As the MCMC gives us the whole posterior distribution of the parameters, we can make use of statistics such as the posterior means or medians, and plug them into the mean-variance optimizer to obtain portfolio weights.</p>
</section>
<section id="additional-references-for-this-section">
<h2>Additional references for this section<a class="headerlink" href="#additional-references-for-this-section" title="Permalink to this heading">#</a></h2>
<p>Idzorek, T. (2007). A step-by-step guide to the Black-Litterman model: Incorporating user-specified confidence levels. In <em>Forecasting expected returns in the financial markets</em> (pp. 17-38). Academic Press.</p>
<p>Walters, J. (2014). The Black-Litterman Model in Detail. (<a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1314585">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1314585</a>)</p>
<p>Schepel, J.F. (2019), Bayesian Extensions of the Black-Litterman Model. (<a class="reference external" href="https://thesis.eur.nl/pub/49562/20190827-Final-thesis-J.F.-Schepel-483851js-.pdf">https://thesis.eur.nl/pub/49562/20190827-Final-thesis-J.F.-Schepel-483851js-.pdf</a>)</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="CH1.2_bayes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bayesian inference and computation</p>
      </div>
    </a>
    <a class="right-next"
       href="CH2_cross_section.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 2: The cross section of asset returns</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incorporating-subjective-views">Incorporating subjective views</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conjugate-priors-versus-mcmc">Conjugate priors versus MCMC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-references-for-this-section">Additional references for this section</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Thomas Martins
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  This book is available under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International license.
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>